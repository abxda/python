{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2ERVvzqLaA9YM80/6gyk/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/python/blob/main/UP_Semana_4_Viernes_y_S%C3%A1bado_01_Nacional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rA_RRKyqVgr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from zipfile import ZipFile\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "from shapely.geometry import Polygon\n",
        "from math import sin, cos, radians, sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import folium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download(url, directory):\n",
        "    filename = url.split('/')[-1]\n",
        "    filepath = os.path.join(directory, filename)\n",
        "\n",
        "    # Verificar si el archivo ya existe\n",
        "    if os.path.exists(filepath):\n",
        "        print(f\"El archivo {filename} ya existe, no se descarga de nuevo.\")\n",
        "        return\n",
        "\n",
        "    # Proceso de descarga\n",
        "    time.sleep(5)  # Simular retardo en la red\n",
        "    r = requests.get(url, stream=True)\n",
        "    total_size = int(r.headers['content-length'])\n",
        "    with open(filepath, 'wb') as f:\n",
        "        for data in tqdm(iterable=r.iter_content(chunk_size=1024), total=total_size / 1024, unit='KB'):\n",
        "            f.write(data)"
      ],
      "metadata": {
        "id": "sF-v2uXKqa2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_shapefile(estados_geo, directory, shp_dir, shape_type):\n",
        "    for estado in estados_geo:\n",
        "        file = estado.split('_')[0]\n",
        "        zip_file = os.path.join(directory, estado)\n",
        "        shp_files = [\n",
        "            f'conjunto_de_datos/{file}{shape_type}.shp',\n",
        "            f'conjunto_de_datos/{file}{shape_type}.cpg',\n",
        "            f'conjunto_de_datos/{file}{shape_type}.dbf',\n",
        "            f'conjunto_de_datos/{file}{shape_type}.prj',\n",
        "            f'conjunto_de_datos/{file}{shape_type}.shx'\n",
        "        ]\n",
        "\n",
        "        # Verificar si todos los archivos necesarios ya están descomprimidos\n",
        "        if all(os.path.exists(os.path.join(shp_dir, f)) for f in shp_files):\n",
        "            print(f\"Todos los archivos para {file} ya están descomprimidos en {shp_dir}\")\n",
        "            continue\n",
        "\n",
        "        # Proceso de descompresión\n",
        "        with ZipFile(zip_file, 'r') as zip:\n",
        "            for f in shp_files:\n",
        "                try:\n",
        "                    zip.extract(f, shp_dir)\n",
        "                except KeyError:\n",
        "                    if f.endswith('.cpg'):  # Archivo CPG es opcional\n",
        "                        with open(os.path.join(shp_dir, f), 'w') as out_file:\n",
        "                            out_file.write(\"ISO 88591\")\n",
        "                    else:\n",
        "                        print(f\"El archivo {f} no se encontró en el ZIP.\")"
      ],
      "metadata": {
        "id": "nEMkckSOrOWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estados_geo = [\"01_aguascalientes.zip\",\"02_bajacalifornia.zip\",\"03_bajacaliforniasur.zip\",\"04_campeche.zip\",\"05_coahuiladezaragoza.zip\",\"06_colima.zip\",\"07_chiapas.zip\",\"08_chihuahua.zip\",\"09_ciudaddemexico.zip\",\"10_durango.zip\",\"11_guanajuato.zip\",\"12_guerrero.zip\",\"13_hidalgo.zip\",\"14_jalisco.zip\",\"15_mexico.zip\",\"16_michoacandeocampo.zip\",\"17_morelos.zip\",\"18_nayarit.zip\",\"19_nuevoleon.zip\",\"20_oaxaca.zip\",\"21_puebla.zip\",\"22_queretaro.zip\",\"23_quintanaroo.zip\",\"24_sanluispotosi.zip\",\"25_sinaloa.zip\",\"26_sonora.zip\",\"27_tabasco.zip\",\"28_tamaulipas.zip\",\"29_tlaxcala.zip\",\"30_veracruzignaciodelallave.zip\",\"31_yucatan.zip\",\"32_zacatecas.zip\"]\n",
        "estados_num = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13 ,14 ,15, 16, 17, 18, 19, 20, 21, 22, 23 ,24, 25, 26, 27, 28, 29, 30, 31, 32]"
      ],
      "metadata": {
        "id": "iI8ZV5F6rRwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_directory = \"./inegi/ccpvagebmza/\"\n",
        "csv_directory = download_directory + \"csv/\"\n",
        "\n",
        "os.makedirs(download_directory, exist_ok=True)\n",
        "os.makedirs(csv_directory, exist_ok=True)\n",
        "os.makedirs(\"./inegi/mgccpv/gpkg\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "dn7GjJqFrURR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar datos estadísticos por estado\n",
        "for i in estados_num:\n",
        "    estado = str(i).zfill(2)\n",
        "    zip_file_path = f'{download_directory}ageb_mza_urbana_{estado}_cpv2020_csv.zip'\n",
        "    csv_file_path = f'{csv_directory}conjunto_de_datos/conjunto_de_datos_ageb_urbana_{estado}_cpv2020.csv'\n",
        "\n",
        "    # Comprobar si el archivo CSV ya ha sido extraído\n",
        "    if not os.path.exists(csv_file_path):\n",
        "        url = f'https://www.inegi.org.mx/contenidos/programas/ccpv/2020/datosabiertos/ageb_manzana/ageb_mza_urbana_{estado}_cpv2020_csv.zip'\n",
        "\n",
        "        # Comprobar si el archivo ZIP ya existe antes de descargarlo\n",
        "        if not os.path.exists(zip_file_path):\n",
        "            download(url, download_directory)  # Asegúrate de que la función `download` acepte el directorio de destino\n",
        "        # Descomprimir el archivo CSV específico si el ZIP ya está disponible\n",
        "        with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extract(f'ageb_mza_urbana_{estado}_cpv2020/conjunto_de_datos/conjunto_de_datos_ageb_urbana_{estado}_cpv2020.csv', csv_directory)\n",
        "    else:\n",
        "        print(f'El archivo CSV para el estado {estado} ya existe y no se descargará ni descomprimirá de nuevo.')"
      ],
      "metadata": {
        "id": "yyWSvV2BrX0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_mgccpv = \"https://www.inegi.org.mx/contenidos/productos/prod_serv/contenidos/espanol/bvinegi/productos/geografia/marcogeo/889463807469/\"\n",
        "for state in estados_geo:\n",
        "    download(url_mgccpv + state, \"./inegi/mgccpv\")\n",
        "\n",
        "# Manzanas\n",
        "shape_type = \"m\"\n",
        "directory= \"./inegi/mgccpv/\"\n",
        "shp_dir = directory+\"shp/m/\"\n",
        "extract_shapefile(estados_geo,directory,shp_dir,shape_type)"
      ],
      "metadata": {
        "id": "rFHSpszMrdml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for estado in estados_geo:\n",
        "    file = estado.split('_')[0]\n",
        "    print(\"procesando estado: \"+ file)\n",
        "    gpdf = gpd.read_file(f\"./inegi/mgccpv/shp/m/conjunto_de_datos/{file}m.shp\")\n",
        "    df = pd.read_csv(f\"./inegi/ccpvagebmza/csv/ageb_mza_urbana_{file}_cpv2020/conjunto_de_datos/conjunto_de_datos_ageb_urbana_{file}_cpv2020.csv\",na_values=['N/A','N/D','*'])\n",
        "    df = df[[\"ENTIDAD\", \"MUN\", \"LOC\", \"AGEB\", \"MZA\",\"POBTOT\", \"P_15A17\", \"P_18A24\"]]\n",
        "    df['CVEGEO'] = df.apply(lambda row: str(row['ENTIDAD']).zfill(2) + str(row['MUN']).zfill(3)+ str(row['LOC']).zfill(4)+ str(row['AGEB']).zfill(4)+ str(row['MZA']).zfill(3), axis=1)\n",
        "    df_geo_censo = pd.merge(df, gpdf, how = 'left').drop([\"CVE_ENT\", \"CVE_MUN\", \"CVE_LOC\", \"CVE_AGEB\", \"CVE_MZA\"], axis = 1)\n",
        "    df_geo_censo = df_geo_censo.drop(df[df.MZA == 0].index)\n",
        "    df_geo_censo = gpd.GeoDataFrame(df_geo_censo, geometry=\"geometry\")\n",
        "    print(\"guardando datos del estado: \"+str(estado))\n",
        "    df_geo_censo.to_file(f\"./inegi/mgccpv/gpkg/cpv2020_{file}.shp\")"
      ],
      "metadata": {
        "id": "XyzlD3gD0Fbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "for estado in estados_geo:\n",
        "    file = estado.split('_')[0]\n",
        "    gdf = gpd.read_file(f\"./inegi/mgccpv/gpkg/cpv2020_{file}.shp\")\n",
        "    dfs.append(gdf)\n",
        "\n",
        "censo_df = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "5hNQPhqE10-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "censo_df.loc[:, 'centroid'] = censo_df['geometry'].centroid"
      ],
      "metadata": {
        "id": "hWxGf-mP9IoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "censo_df_centroide = censo_df.set_geometry('centroid')"
      ],
      "metadata": {
        "id": "-xyitTdq9k1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "censo_df_centroide.drop(columns=[\"geometry\"], inplace=True)"
      ],
      "metadata": {
        "id": "BJKGpubk9vjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "censo_df_centroide"
      ],
      "metadata": {
        "id": "8oP8PrOzATI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "censo_df_centroide.to_file(f\"./inegi/mgccpv/gpkg/cpv2020_centroides_INE.shp\")"
      ],
      "metadata": {
        "id": "vWIwIIp4AVXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5LAGDBIDA5pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6bBEF-CDlW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}