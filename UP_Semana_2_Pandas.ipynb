{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCghC/mEjwZWRTpt4dJQee",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/python/blob/main/UP_Semana_2_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwibKICGGuH1"
      },
      "outputs": [],
      "source": [
        "# Importaciones básicas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(f\"Versión de Pandas instalada: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Creación de Series ---\")\n",
        "\n",
        "# 1. Serie a partir de una lista (índice numérico automático)\n",
        "serie_numeros = pd.Series([10, 20, 30, 40, 50])\n",
        "print(\"Serie creada desde una lista:\")\n",
        "print(serie_numeros)\n",
        "print(f\"Tipo de datos: {serie_numeros.dtype}\")\n",
        "print(f\"Índice: {serie_numeros.index}\\n\") # Nota el índice por defecto\n"
      ],
      "metadata": {
        "id": "-AZbkUk5fP13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Serie a partir de otra lista (cadenas)\n",
        "serie_letras = pd.Series([\"a\", \"b\", \"c\"])\n",
        "print(\"Serie creada desde una lista de strings:\")\n",
        "print(serie_letras)\n",
        "print(f\"Tipo de datos: {serie_letras.dtype}\") # 'object' usualmente indica strings o tipos mixtos\n",
        "print(f\"Índice: {serie_letras.index}\\n\")"
      ],
      "metadata": {
        "id": "xRQRip__fP5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Variación: Serie a partir de un diccionario\n",
        "# Las claves del diccionario se convierten en el índice\n",
        "datos_dict = {'Manzana': 5, 'Plátano': 8, 'Naranja': 3}\n",
        "serie_frutas = pd.Series(datos_dict)\n",
        "print(\"Serie creada desde un diccionario:\")\n",
        "print(serie_frutas)\n",
        "print(f\"Índice: {serie_frutas.index}\\n\")"
      ],
      "metadata": {
        "id": "2OoBaOnDG3L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Índices Personalizados en Series ---\")\n",
        "\n",
        "# 1. Crear un objeto Index explícito (aunque no siempre es necesario)\n",
        "idx_ciudades = pd.Index([\"Tijuana\", \"Juárez\", \"Gustavo A. Madero\", \"Iztapalapa\", \"León de los Aldama\",\n",
        "                         \"Guadalajara\", \"Zapopan\", \"Ecatepec de Morelos\", \"Monterrey\", \"Heroica Puebla de Zaragoza\"])\n",
        "print(\"Objeto Index creado:\")\n",
        "print(idx_ciudades)\n",
        "print(f\"Tipo: {type(idx_ciudades)}\\n\")\n",
        "\n",
        "# 2. Crear una Serie usando el índice personalizado y dándole un nombre\n",
        "poblacion_lista = [1810645, 1501551, 1173351, 1835486, 1579803,\n",
        "                   1385621, 1257547, 1643623, 1142952, 1542232]\n",
        "pob = pd.Series(poblacion_lista, index=idx_ciudades, name=\"Población\") # Añadimos nombre descriptivo\n",
        "print(\"Serie con índice personalizado (Ciudades):\")\n",
        "print(pob)\n",
        "print(f\"\\nNombre de la Serie: {pob.name}\")\n",
        "print(f\"Índice de la Serie: {pob.index}\")\n",
        "print(f\"Valores de la Serie (como array NumPy): {pob.values}\\n\")\n"
      ],
      "metadata": {
        "id": "LYe4JIodli2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Variación: Crear la Serie directamente con índice de strings\n",
        "puntuaciones = pd.Series([9.5, 8.0, 7.5, 9.0], index=['Ana', 'Luis', 'Eva', 'Juan'], name='Calificaciones')\n",
        "print(\"Otra Serie con índice personalizado (Nombres):\")\n",
        "print(puntuaciones)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "o9wDlVlOG_l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Acceso por Posición (iloc implícito) ---\")\n",
        "\n",
        "# Reutilizamos la serie numérica sin índice personalizado\n",
        "serie = pd.Series([10, 20, 30, 40, 50])\n",
        "print(f\"Serie original:\\n{serie}\\n\")\n",
        "\n",
        "# 1. Acceder al elemento en la posición 2 (el tercer elemento)\n",
        "elemento_pos_2 = serie[2]\n",
        "print(f\"Elemento en la posición 2: {elemento_pos_2}\\n\")\n"
      ],
      "metadata": {
        "id": "fGpyrI4mmYM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Acceso por Etiqueta de Índice (loc implícito) ---\")\n",
        "\n",
        "# Reutilizamos la serie con índice de letras\n",
        "serie_con_indice = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
        "print(f\"Serie original con índice:\\n{serie_con_indice}\\n\")\n",
        "\n",
        "# 1. Acceder al elemento con la etiqueta 'b'\n",
        "elemento_b = serie_con_indice['b']\n",
        "print(f\"Elemento con etiqueta 'b': {elemento_b}\\n\")\n",
        "\n",
        "\n",
        "# 2. Variación: Acceder a un rango de elementos (slicing)\n",
        "# Desde la posición 1 hasta la 3 (sin incluir la 4)\n",
        "slice_pos = serie[1:4]\n",
        "print(\"Elementos desde la posición 1 hasta la 3:\")\n",
        "print(slice_pos)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Variación: Acceder a posiciones específicas\n",
        "# Nota: Para acceso explícito por posición, especialmente si hay índices personalizados,\n",
        "# se prefiere usar .iloc (veremos más adelante con DataFrames)\n",
        "print(f\"Acceso implícito a posición 0: {serie[0]}\")\n",
        "print(f\"Acceso implícito a última posición: {serie[len(serie)-1]} o {serie.iloc[-1]}\\n\")"
      ],
      "metadata": {
        "id": "gw-lxYlcnBMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Selección y Filtrado (Condiciones Booleanas) ---\")\n",
        "\n",
        "# Reutilizamos la serie numérica\n",
        "serie = pd.Series([10, 20, 30, 40, 50])\n",
        "print(f\"Serie original:\\n{serie}\\n\")\n",
        "\n",
        "# 1. Seleccionar elementos mayores que 25\n",
        "condicion = serie > 25\n",
        "print(f\"La condición (Serie Booleana):\\n{condicion}\\n\")\n",
        "filtrados_mayores_25 = serie[condicion] # O directamente serie[serie > 25]\n",
        "print(\"Elementos mayores que 25:\")\n",
        "print(filtrados_mayores_25)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Variación: Seleccionar elementos pares\n",
        "filtrados_pares = serie[serie % 2 == 0]\n",
        "print(\"Elementos pares:\")\n",
        "print(filtrados_pares)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Variación con la serie de población: Ciudades con más de 1.5 millones de habitantes\n",
        "pob_mas_1_5M = pob[pob > 1500000]\n",
        "print(\"Ciudades con más de 1.5 millones de habitantes:\")\n",
        "print(pob_mas_1_5M)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "omeSV17knBPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Asignación de Valores ---\")\n",
        "\n",
        "# Reutilizamos la serie con índice de letras\n",
        "serie_con_indice = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
        "print(f\"Serie original:\\n{serie_con_indice}\\n\")\n",
        "\n",
        "# 1. Asignar un nuevo valor usando la etiqueta de índice\n",
        "print(\"Asignando el valor 10 a la etiqueta 'b'...\")\n",
        "serie_con_indice['b'] = 10\n",
        "print(\"Serie modificada:\")\n",
        "print(serie_con_indice)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Variación: Asignar un valor usando la posición\n",
        "serie_numeros = pd.Series([100, 200, 300])\n",
        "print(f\"Otra serie:\\n{serie_numeros}\\n\")\n",
        "print(\"Asignando 999 a la posición 0...\")\n",
        "serie_numeros[0] = 999\n",
        "print(\"Serie modificada:\")\n",
        "print(serie_numeros)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Variación: Asignar un valor basado en una condición\n",
        "serie = pd.Series([10, 20, 30, 40, 50])\n",
        "print(f\"Serie original para asignación condicional:\\n{serie}\\n\")\n",
        "print(\"Asignando 0 a los elementos <= 20...\")\n",
        "serie[serie <= 20] = 0\n",
        "print(\"Serie modificada:\")\n",
        "print(serie)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "01DMOj-aoXWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#*****"
      ],
      "metadata": {
        "id": "moTAqSjrp4es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Definición y Creación de un DataFrame ---\")\n",
        "\n",
        "# 1. Crear un DataFrame a partir de un diccionario de listas\n",
        "# Cada clave es un nombre de columna, cada lista son los datos de esa columna\n",
        "data_dict = {\n",
        "    'Año': [2020, 2021, 2022, 2023],\n",
        "    'Población': [100, 150, 200, 250],\n",
        "    'PIB': [1.0, 1.2, 1.5, 1.6]\n",
        "}\n",
        "df_dict = pd.DataFrame(data_dict)\n",
        "print(\"DataFrame creado desde un diccionario de listas:\")\n",
        "print(df_dict)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Variación: Crear un DataFrame a partir de una lista de listas\n",
        "# Se deben proporcionar los nombres de las columnas por separado\n",
        "datos_listas = [['Ana', 25, 'Madrid'], ['Luis', 30, 'Barcelona'], ['Carlos', 35, 'Valencia']]\n",
        "columnas = ['Nombre', 'Edad', 'Ciudad']\n",
        "df_listas = pd.DataFrame(datos_listas, columns=columnas)\n",
        "print(\"DataFrame creado desde una lista de listas:\")\n",
        "print(df_listas)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Variación: Crear DataFrame desde una Serie\n",
        "print(\"DataFrame creado desde la Serie de Población:\")\n",
        "df_pob = pd.DataFrame(pob) # Convierte la Serie en un DF de una columna\n",
        "print(df_pob)\n",
        "# Para darle un nombre más explícito a la columna:\n",
        "df_pob_named = pd.DataFrame({'Población': pob})\n",
        "print(\"\\nDataFrame desde Serie con nombre de columna explícito:\")\n",
        "print(df_pob_named)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "qSurXMltHjZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Manejo de Índices y Columnas ---\")\n",
        "\n",
        "# Reutilizamos el DataFrame creado desde el diccionario\n",
        "dataframe = pd.DataFrame({\n",
        "    'Año': [2020, 2021, 2022],\n",
        "    'Población': [100, 150, 200]\n",
        "})\n",
        "print(f\"DataFrame original:\\n{dataframe}\\n\")\n",
        "print(f\"Índice original: {dataframe.index}\")\n",
        "print(f\"Columnas originales: {dataframe.columns}\\n\")\n",
        "\n",
        "# 1. Establecer una columna ('Año') como el índice de filas\n",
        "# 'inplace=True' modificaría el DataFrame original directamente\n",
        "df_con_indice = dataframe.set_index('Año')\n",
        "# Alternativamente: dataframe.set_index('Año', inplace=True)\n",
        "print(\"DataFrame con 'Año' como índice:\")\n",
        "print(df_con_indice)\n",
        "print(f\"Nuevo índice: {df_con_indice.index}\\n\")\n",
        "\n",
        "# 2. Acceso a columnas\n",
        "# Se accede a las columnas por su nombre, como en un diccionario\n",
        "columna_poblacion = dataframe['Población'] # Nota: Usamos el DF original sin el índice cambiado\n",
        "print(\"Acceso a la columna 'Población' (esto es una Serie):\")\n",
        "print(columna_poblacion)\n",
        "print(f\"Tipo: {type(columna_poblacion)}\\n\")\n",
        "\n",
        "# 3. Variación: Acceder a múltiples columnas\n",
        "# Pasamos una lista de nombres de columnas\n",
        "columnas_seleccionadas = dataframe[['Año', 'Población']] # Devuelve un DataFrame\n",
        "print(\"Acceso a las columnas 'Año' y 'Población':\")\n",
        "print(columnas_seleccionadas)\n",
        "print(f\"Tipo: {type(columnas_seleccionadas)}\\n\")\n",
        "\n",
        "# 4. Volver del índice a una columna regular\n",
        "df_resetado = df_con_indice.reset_index()\n",
        "print(\"DataFrame después de resetear el índice:\")\n",
        "print(df_resetado)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "gfgFdk4cHnEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Exploración Inicial del DataFrame ---\")\n",
        "\n",
        "# Usaremos el DataFrame de población creado anteriormente\n",
        "df = pd.DataFrame({\n",
        "    'Nombre': ['Ana', 'Luis', 'Carlos', 'Eva', 'Juan', 'Sofia', 'Pedro'],\n",
        "    'Edad': [25, 30, 35, 25, 30, 40, 35],\n",
        "    'Ciudad': ['Madrid', 'Barcelona', 'Madrid', 'Valencia', 'Madrid', 'Barcelona', 'Sevilla'],\n",
        "    'Puntuacion': [8.5, 9.0, 7.5, 8.5, 9.5, 8.0, 7.0]\n",
        "})\n",
        "print(f\"DataFrame de ejemplo para exploración:\\n{df}\\n\")\n",
        "\n",
        "# 1. Ver las primeras filas (por defecto 5)\n",
        "print(\"Primeras 3 filas (.head(3)):\")\n",
        "print(df.head(3))\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Ver las últimas filas (por defecto 5)\n",
        "print(\"Últimas 2 filas (.tail(2)):\")\n",
        "print(df.tail(2))\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Obtener información general (tipos de datos, memoria, valores no nulos)\n",
        "print(\"Información general (.info()):\")\n",
        "df.info() # info() imprime directamente, no devuelve un objeto imprimible\n",
        "print(\"\\n\")\n",
        "\n",
        "# 4. Resumen estadístico para columnas numéricas\n",
        "print(\"Resumen estadístico (.describe()):\")\n",
        "print(df.describe())\n",
        "print(\"\\n\")\n",
        "\n",
        "# 5. Variación: Resumen estadístico para todas las columnas (incluyendo categóricas/object)\n",
        "print(\"Resumen estadístico para todas las columnas (.describe(include='all')):\")\n",
        "print(df.describe(include='all'))\n",
        "print(\"\\n\")\n",
        "\n",
        "# 6. Dimensiones del DataFrame (filas, columnas)\n",
        "print(f\"Dimensiones del DataFrame (.shape): {df.shape}\")\n",
        "print(f\"Número de filas: {df.shape[0]}, Número de columnas: {df.shape[1]}\\n\")\n",
        "\n",
        "# 7. Nombres de las columnas\n",
        "print(f\"Nombres de las columnas (.columns): {df.columns}\\n\")\n",
        "\n",
        "# 8. Tipos de datos de cada columna\n",
        "print(\"Tipos de datos por columna (.dtypes):\")\n",
        "print(df.dtypes)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 9. Explorar valores únicos en una columna específica\n",
        "print(\"Valores únicos en la columna 'Ciudad' (.unique()):\")\n",
        "print(df['Ciudad'].unique())\n",
        "print(\"\\n\")\n",
        "\n",
        "# 10. Variación: Contar la frecuencia de cada valor único en una columna\n",
        "print(\"Frecuencia de valores en 'Ciudad' (.value_counts()):\")\n",
        "print(df['Ciudad'].value_counts())\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "yvNvEwnUHqv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Importando Datos Externos ---\")\n",
        "\n",
        "# 1. Cargar datos desde un archivo CSV en una URL\n",
        "# El archivo debe ser accesible públicamente\n",
        "url_csv = 'https://raw.githubusercontent.com/abxda/python/main/datos.csv'\n",
        "print(f\"Cargando CSV desde: {url_csv}\")\n",
        "try:\n",
        "    df_csv = pd.read_csv(url_csv)\n",
        "    print(\"DataFrame cargado desde CSV:\")\n",
        "    print(df_csv.head()) # Mostramos solo las primeras filas\n",
        "except Exception as e:\n",
        "    print(f\"Error al cargar CSV: {e}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Cargar datos desde un archivo Excel en una URL\n",
        "# Puede requerir la instalación de 'openpyxl' o 'xlrd': pip install openpyxl\n",
        "url_excel = \"https://raw.githubusercontent.com/abxda/python/main/datos.xlsx\"\n",
        "print(f\"Cargando Excel desde: {url_excel}\")\n",
        "try:\n",
        "    # Especificamos la hoja que queremos leer\n",
        "    df_excel = pd.read_excel(url_excel, sheet_name='datos')\n",
        "    print(\"DataFrame cargado desde Excel (hoja 'datos'):\")\n",
        "    print(df_excel.head())\n",
        "except Exception as e:\n",
        "    print(f\"Error al cargar Excel: {e}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Cargar datos desde una base de datos SQLite\n",
        "# Nota: El comando !wget es para entornos tipo Colab/Jupyter para descargar el archivo.\n",
        "# En un script local, necesitarías descargar el archivo manualmente o usar librerías como requests.\n",
        "# ¡Descomenta la siguiente línea si estás en un entorno compatible y quieres descargar el archivo!\n",
        "!wget http://2016.padjo.org/files/data/starterpack/simplefolks.sqlite -O simplefolks.sqlite\n",
        "\n",
        "import sqlite3\n",
        "import os\n",
        "\n",
        "db_filename = \"simplefolks.sqlite\"\n",
        "print(f\"Intentando conectar a la base de datos: {db_filename}\")\n",
        "\n",
        "# Verificamos si el archivo existe antes de intentar conectar\n",
        "if os.path.exists(db_filename):\n",
        "    try:\n",
        "        conexion = sqlite3.connect(db_filename)\n",
        "\n",
        "        # a) Consultar las tablas disponibles\n",
        "        sql_query_tablas = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
        "        df_tablas = pd.read_sql(sql_query_tablas, conexion)\n",
        "        print(\"Tablas encontradas en la base de datos:\")\n",
        "        print(df_tablas)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # b) Leer datos de la tabla 'pets'\n",
        "        sql_query_pets = \"SELECT * FROM pets;\"\n",
        "        df_pets = pd.read_sql(sql_query_pets, conexion)\n",
        "        print(\"Primeras filas de la tabla 'pets':\")\n",
        "        print(df_pets.head())\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # c) Leer datos de la tabla 'homes'\n",
        "        sql_query_homes = \"SELECT * FROM homes;\"\n",
        "        df_homes = pd.read_sql(sql_query_homes, conexion)\n",
        "        print(\"Primeras filas de la tabla 'homes':\")\n",
        "        print(df_homes.head())\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # Es buena práctica cerrar la conexión\n",
        "        conexion.close()\n",
        "        print(\"Conexión a la base de datos cerrada.\")\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"Error de SQLite: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Otro error al procesar SQLite: {e}\")\n",
        "else:\n",
        "    print(f\"Archivo de base de datos '{db_filename}' no encontrado. Omitiendo carga desde SQL.\")\n",
        "\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "QvwCj6eiHs1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jbLCoA785I5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Semana 2 Pandas"
      ],
      "metadata": {
        "id": "Gm4a7Onxt2MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FDj_ru3k5IKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Identificación de Valores Faltantes (NaN) ---\")\n",
        "\n",
        "# 1. Crear un DataFrame de ejemplo con valores faltantes (NaN)\n",
        "data_nan = {\n",
        "    'A': [10, 20, np.nan, 40, 50],\n",
        "    'B': [np.nan, 30, 40, np.nan, 60],\n",
        "    'C': [50, np.nan, 70, 80, np.nan],\n",
        "    'D': [1, 2, 3, 4, 5] # Columna sin NaN para comparar\n",
        "}\n",
        "df_nan = pd.DataFrame(data_nan)\n",
        "print(f\"DataFrame con valores NaN:\\n{df_nan}\\n\")\n",
        "\n",
        "# 2. Identificar valores faltantes (devuelve DataFrame booleano)\n",
        "valores_faltantes_bool = df_nan.isnull()\n",
        "print(\"Identificación de NaN (True donde falta valor):\")\n",
        "print(valores_faltantes_bool)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Contabilizar el número de valores faltantes por columna\n",
        "faltantes_por_columna = valores_faltantes_bool.sum() # O df_nan.isnull().sum()\n",
        "print(\"Número de NaN por columna:\")\n",
        "print(faltantes_por_columna)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 4. Contabilizar el total de valores faltantes en todo el DataFrame\n",
        "total_faltantes = faltantes_por_columna.sum() # O df_nan.isnull().sum().sum()\n",
        "print(f\"Número total de NaN en el DataFrame: {total_faltantes}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# 5. Variación: Usar notnull() para ver los valores NO faltantes\n",
        "valores_no_faltantes = df_nan.notnull()\n",
        "print(\"Identificación de valores NO faltantes (True donde hay valor):\")\n",
        "print(valores_no_faltantes)\n",
        "print(f\"Total de valores NO faltantes: {df_nan.notnull().sum().sum()}\")\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "W_Jry2yZHu__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Combinando DataFrames con pd.concat ---\")\n",
        "\n",
        "# Crear dos DataFrames de ejemplo simples\n",
        "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]}, index=['f1', 'f2'])\n",
        "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]}, index=['f3', 'f4'])\n",
        "df3 = pd.DataFrame({'C': [11, 12], 'D': [13, 14]}, index=['f1', 'f2']) # Mismo índice que df1\n",
        "\n",
        "print(f\"DataFrame 1:\\n{df1}\\n\")\n",
        "print(f\"DataFrame 2:\\n{df2}\\n\")\n",
        "print(f\"DataFrame 3 (mismo índice que df1):\\n{df3}\\n\")\n",
        "\n",
        "# 1. Concatenación Vertical (apilar filas, axis=0 por defecto)\n",
        "# Une df2 debajo de df1. Las columnas deben coincidir idealmente.\n",
        "df_vertical = pd.concat([df1, df2]) # axis=0 es el default\n",
        "print(\"Concatenación Vertical (axis=0):\")\n",
        "print(df_vertical)\n",
        "print(\"Observa cómo se mantienen los índices originales.\\n\")\n",
        "\n",
        "# 2. Variación Vertical: Ignorar índices originales y crear uno nuevo\n",
        "df_vertical_reset = pd.concat([df1, df2], ignore_index=True)\n",
        "print(\"Concatenación Vertical con ignore_index=True:\")\n",
        "print(df_vertical_reset)\n",
        "print(\"Observa el nuevo índice numérico secuencial.\\n\")\n",
        "\n",
        "# 3. Concatenación Horizontal (unir columnas, axis=1)\n",
        "# Une las columnas de df3 al lado de las de df1. Los índices de fila deben coincidir.\n",
        "df_horizontal = pd.concat([df1, df3], axis=1)\n",
        "print(\"Concatenación Horizontal (axis=1):\")\n",
        "print(df_horizontal)\n",
        "print(\"Observa cómo se alinean las filas por su índice ('f1', 'f2').\\n\")\n",
        "\n",
        "# 4. Variación Horizontal: ¿Qué pasa si los índices no coinciden perfectamente?\n",
        "df4 = pd.DataFrame({'E': [100, 200]}, index=['f2', 'f5']) # Índice parcialmente coincidente con df1\n",
        "print(f\"DataFrame 4 (índice parcial):\\n{df4}\\n\")\n",
        "df_horizontal_nan = pd.concat([df1, df4], axis=1)\n",
        "print(\"Concatenación Horizontal con índices no coincidentes:\")\n",
        "print(df_horizontal_nan)\n",
        "print(\"Observa cómo se introducen NaN donde no hay coincidencia de índice.\\n\")"
      ],
      "metadata": {
        "id": "JNq1QXOvIK1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Selección Avanzada y Filtros ---\")\n",
        "\n",
        "# Reutilizamos el DataFrame de ejemplo\n",
        "df = pd.DataFrame({\n",
        "    'Nombre': ['Ana', 'Bruno', 'Carlos', 'Diana', 'Eva'],\n",
        "    'Edad': [25, 30, 35, 22, 28],\n",
        "    'Ciudad': ['Madrid', 'Barcelona', 'Madrid', 'Valencia', 'Madrid'],\n",
        "    'Puntuacion': [8.5, 9.1, 7.8, 8.8, 9.5]\n",
        "}, index=['id1', 'id2', 'id3', 'id4', 'id5']) # Añadimos un índice de etiquetas\n",
        "print(f\"DataFrame de ejemplo con índice:\\n{df}\\n\")\n",
        "\n",
        "# --- Filtros Booleanos ---\n",
        "print(\"--- Filtros Booleanos ---\")\n",
        "# 1. Filtrar por una condición simple (como en Series)\n",
        "df_jovenes = df[df['Edad'] < 30]\n",
        "print(\"Personas con menos de 30 años:\")\n",
        "print(df_jovenes)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Filtrar por múltiples condiciones (usando & para AND)\n",
        "# Nota los paréntesis alrededor de cada condición\n",
        "df_filtrado_and = df[(df['Edad'] > 25) & (df['Ciudad'] == 'Madrid')]\n",
        "print(\"Personas de Madrid mayores de 25 años:\")\n",
        "print(df_filtrado_and)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Variación: Filtrar con OR (usando |)\n",
        "df_filtrado_or = df[(df['Ciudad'] == 'Barcelona') | (df['Puntuacion'] > 9.0)]\n",
        "print(\"Personas de Barcelona O con puntuación mayor a 9.0:\")\n",
        "print(df_filtrado_or)\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- Selección con .loc (basada en ETIQUETAS) ---\n",
        "print(\"--- Selección con .loc (Etiquetas) ---\")\n",
        "# 1. Seleccionar una fila por su etiqueta de índice\n",
        "fila_id2 = df.loc['id2']\n",
        "print(f\"Fila con índice 'id2' (devuelve una Serie):\\n{fila_id2}\\n\")\n",
        "\n",
        "# 2. Seleccionar múltiples filas por etiqueta de índice\n",
        "filas_id1_id4 = df.loc[['id1', 'id4']]\n",
        "print(f\"Filas con índice 'id1' e 'id4' (devuelve DataFrame):\\n{filas_id1_id4}\\n\")\n",
        "\n",
        "# 3. Seleccionar filas y columnas específicas por etiqueta\n",
        "# Formato: df.loc[etiquetas_filas, etiquetas_columnas]\n",
        "seleccion_loc = df.loc[['id1', 'id3', 'id5'], ['Nombre', 'Puntuacion']]\n",
        "print(\"Filas 'id1', 'id3', 'id5' y columnas 'Nombre', 'Puntuacion':\")\n",
        "print(seleccion_loc)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 4. Variación loc: Seleccionar filas basadas en condición y columnas específicas\n",
        "seleccion_loc_cond = df.loc[df['Edad'] < 30, ['Nombre', 'Ciudad']]\n",
        "print(\"Personas < 30 años (loc), mostrando Nombre y Ciudad:\")\n",
        "print(seleccion_loc_cond)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 5. Variación loc: Slicing con etiquetas de índice (incluye el final)\n",
        "slice_loc = df.loc['id2':'id4', 'Edad':'Puntuacion'] # Incluye 'id4' y 'Puntuacion'\n",
        "print(\"Slice de filas 'id2' a 'id4' y columnas 'Edad' a 'Puntuacion':\")\n",
        "print(slice_loc)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# --- Selección con .iloc (basada en POSICIÓN NUMÉRICA) ---\n",
        "print(\"--- Selección con .iloc (Posición) ---\")\n",
        "# 1. Seleccionar la fila en la posición 0 (la primera fila)\n",
        "fila_pos_0 = df.iloc[0]\n",
        "print(f\"Fila en posición 0 (devuelve Serie):\\n{fila_pos_0}\\n\")\n",
        "\n",
        "# 2. Seleccionar las filas en las posiciones 1 y 3\n",
        "filas_pos_1_3 = df.iloc[[1, 3]]\n",
        "print(f\"Filas en posiciones 1 y 3 (devuelve DataFrame):\\n{filas_pos_1_3}\\n\")\n",
        "\n",
        "# 3. Seleccionar filas y columnas específicas por posición\n",
        "# Formato: df.iloc[posiciones_filas, posiciones_columnas]\n",
        "# Filas 0 y 2, Columnas 0 ('Nombre') y 3 ('Puntuacion')\n",
        "seleccion_iloc = df.iloc[[0, 2], [0, 3]]\n",
        "print(\"Filas en pos 0, 2 y Columnas en pos 0, 3:\")\n",
        "print(seleccion_iloc)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 4. Variación iloc: Slicing por posición (NO incluye el final, como en Python)\n",
        "# Primeras 3 filas (0, 1, 2) y primeras 2 columnas (0, 1)\n",
        "slice_iloc = df.iloc[0:3, 0:2]\n",
        "print(\"Slice de filas 0 a 2 y columnas 0 a 1:\")\n",
        "print(slice_iloc)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 5. Variación iloc: Seleccionar todas las filas y columnas específicas\n",
        "todas_filas_col_1_2 = df.iloc[:, [1, 2]] # ':' significa todas las filas\n",
        "print(\"Todas las filas, columnas en posición 1 y 2:\")\n",
        "print(todas_filas_col_1_2)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "5XEySYNLILN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Modificación y Creación de Columnas ---\")\n",
        "\n",
        "# Crear un DataFrame de ejemplo\n",
        "df_mod = pd.DataFrame({\n",
        "    'Nombre': ['Ana', 'Bruno', 'Carlos'],\n",
        "    'Edad': [25, 30, 35],\n",
        "    'Puntos_A': [100, 150, 200],\n",
        "    'Puntos_B': [50, 60, 70]\n",
        "})\n",
        "print(f\"DataFrame original:\\n{df_mod}\\n\")\n",
        "\n",
        "# 1. Añadir una nueva columna calculada\n",
        "df_mod['Edad + 10'] = df_mod['Edad'] + 10\n",
        "print(\"DataFrame con nueva columna 'Edad + 10':\")\n",
        "print(df_mod)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Variación: Añadir columna con un valor constante\n",
        "df_mod['Pais'] = 'México'\n",
        "print(\"DataFrame con columna constante 'Pais':\")\n",
        "print(df_mod)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Variación: Modificar una columna existente\n",
        "df_mod['Edad'] = df_mod['Edad'] * 2 # Duplicar la edad\n",
        "print(\"DataFrame con columna 'Edad' modificada (duplicada):\")\n",
        "print(df_mod)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 4. Renombrar una columna\n",
        "# Usamos inplace=True para modificar el df original directamente\n",
        "df_mod.rename(columns={'Edad + 10': 'Edad_Futura', 'Pais': 'Nacionalidad'}, inplace=True)\n",
        "print(\"DataFrame con columnas renombradas ('Edad_Futura', 'Nacionalidad'):\")\n",
        "print(df_mod)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 5. Eliminar columnas\n",
        "# Necesitamos especificar axis=1 para columnas\n",
        "df_mod.drop(['Puntos_A', 'Nacionalidad'], axis=1, inplace=True)\n",
        "print(\"DataFrame después de eliminar 'Puntos_A' y 'Nacionalidad':\")\n",
        "print(df_mod)\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- Uso de apply() ---\n",
        "print(\"--- Uso de apply() ---\")\n",
        "# 6. Definir una función para aplicar a una columna (Serie)\n",
        "def rango_etario(edad):\n",
        "    if edad < 60: # Ajustado por la duplicación anterior\n",
        "        return 'Adulto'\n",
        "    elif edad < 80:\n",
        "        return 'Adulto Mayor'\n",
        "    else:\n",
        "        return 'Anciano'\n",
        "\n",
        "# Aplicar la función a la columna 'Edad' para crear 'Rango Etario'\n",
        "df_mod['Rango Etario'] = df_mod['Edad'].apply(rango_etario)\n",
        "print(\"DataFrame con columna 'Rango Etario' creada con apply():\")\n",
        "print(df_mod)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 7. Variación apply(): Aplicar una función a las filas (axis=1)\n",
        "# Calcular el total de puntos (recreamos Puntos_A para el ejemplo)\n",
        "df_mod['Puntos_A'] = [110, 160, 210]\n",
        "print(f\"DataFrame antes de sumar puntos por fila:\\n{df_mod}\\n\")\n",
        "\n",
        "def sumar_puntos(fila):\n",
        "    # Accedemos a los valores de la fila por su nombre de columna\n",
        "    total = fila['Puntos_A'] + fila['Puntos_B']\n",
        "    return total\n",
        "\n",
        "# axis=1 indica que la función se aplica a cada fila\n",
        "df_mod['Puntos_Total'] = df_mod.apply(sumar_puntos, axis=1)\n",
        "print(\"DataFrame con 'Puntos_Total' calculado por fila con apply(axis=1):\")\n",
        "print(df_mod)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# --- Uso de applymap() ---\n",
        "print(\"--- Uso de applymap() ---\")\n",
        "# 8. Definir una función que opera sobre un único valor\n",
        "def formato_moneda(valor):\n",
        "    # Asegurarse de que sea numérico antes de formatear\n",
        "    if isinstance(valor, (int, float)):\n",
        "        return f\"${valor:,.2f}\" # Formato con comas y 2 decimales\n",
        "    return valor # Devolver el valor original si no es número\n",
        "\n",
        "# Aplicar la función a cada elemento de columnas numéricas específicas\n",
        "columnas_numericas = ['Edad', 'Puntos_B', 'Puntos_A', 'Puntos_Total']\n",
        "df_formateado = df_mod.copy() # Copiar para no alterar el original\n",
        "df_formateado[columnas_numericas] = df_formateado[columnas_numericas].applymap(formato_moneda)\n",
        "print(\"DataFrame con columnas numéricas formateadas usando applymap():\")\n",
        "print(df_formateado)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 9. Variación applymap(): Aplicar a todo el DataFrame (puede dar error si hay tipos no compatibles)\n",
        "def es_string(valor):\n",
        "    return isinstance(valor, str)\n",
        "\n",
        "df_es_string = df_mod.applymap(es_string)\n",
        "print(\"Resultado de applymap(es_string) a todo el DataFrame:\")\n",
        "print(df_es_string)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "dgk6kNtEIQxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Operaciones de Agregación con groupby() ---\")\n",
        "\n",
        "# Crear un DataFrame de ejemplo para agrupaciones\n",
        "df_grupos = pd.DataFrame({\n",
        "    'Categoría': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],\n",
        "    'SubCat': ['X', 'X', 'Y', 'Y', 'X', 'Y', 'Y', 'X'],\n",
        "    'Datos': [10, 20, 30, 40, 50, 60, 70, 80],\n",
        "    'Valores': [1, 5, 2, 6, 3, 7, 4, 8]\n",
        "})\n",
        "print(f\"DataFrame original para agrupar:\\n{df_grupos}\\n\")\n",
        "\n",
        "# 1. Agrupar por 'Categoría' y sumar los 'Datos' para cada grupo\n",
        "grupo_suma_cat = df_grupos.groupby('Categoría')['Datos'].sum()\n",
        "print(\"Suma de 'Datos' por 'Categoría':\")\n",
        "print(grupo_suma_cat)\n",
        "print(f\"Tipo del resultado: {type(grupo_suma_cat)}\\n\") # Devuelve una Serie\n",
        "\n",
        "# 2. Calcular el promedio de 'Datos' por 'Categoría'\n",
        "grupo_promedio_cat = df_grupos.groupby('Categoría')['Datos'].mean()\n",
        "print(\"Promedio de 'Datos' por 'Categoría':\")\n",
        "print(grupo_promedio_cat)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Variación: Agrupar por múltiples columnas ('Categoría' y 'SubCat')\n",
        "# El resultado tendrá un MultiIndex\n",
        "grupo_multi_suma = df_grupos.groupby(['Categoría', 'SubCat'])['Datos'].sum()\n",
        "print(\"Suma de 'Datos' agrupando por 'Categoría' y 'SubCat':\")\n",
        "print(grupo_multi_suma)\n",
        "print(f\"Índice del resultado: {grupo_multi_suma.index}\\n\")\n",
        "\n",
        "# 4. Variación: Aplicar múltiples funciones de agregación a la vez\n",
        "# Usamos el método .agg() con una lista de funciones\n",
        "agregaciones = df_grupos.groupby('Categoría')['Datos'].agg(['sum', 'mean', 'count', 'std'])\n",
        "print(\"Múltiples agregaciones ('sum', 'mean', 'count', 'std') de 'Datos' por 'Categoría':\")\n",
        "print(agregaciones)\n",
        "print(f\"Tipo del resultado: {type(agregaciones)}\\n\") # Devuelve un DataFrame\n",
        "\n",
        "# 5. Variación: Aplicar diferentes agregaciones a diferentes columnas\n",
        "# Pasamos un diccionario a .agg() donde las claves son columnas y los valores son las funciones\n",
        "agregaciones_dict = {\n",
        "    'Datos': ['sum', 'mean'], # Suma y media para 'Datos'\n",
        "    'Valores': 'max'          # Máximo para 'Valores'\n",
        "}\n",
        "agregaciones_multi_col = df_grupos.groupby('Categoría').agg(agregaciones_dict)\n",
        "print(\"Diferentes agregaciones para 'Datos' y 'Valores' por 'Categoría':\")\n",
        "print(agregaciones_multi_col)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 6. Obtener los grupos como un diccionario (menos común, pero útil para inspección)\n",
        "# grupos = dict(list(df_grupos.groupby('Categoría')))\n",
        "# print(\"Grupos como diccionario (clave=Categoría, valor=DataFrame del grupo):\")\n",
        "# print(grupos)\n",
        "# print(\"\\n\")"
      ],
      "metadata": {
        "id": "Vi_-G8ebIUWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Tratamiento de Valores Faltantes (fillna, dropna) ---\")\n",
        "\n",
        "# Reutilizamos el DataFrame con NaN\n",
        "df_nan = pd.DataFrame({\n",
        "    'A': [10, 20, np.nan, 40, 50],\n",
        "    'B': [np.nan, 30, 40, np.nan, 60],\n",
        "    'C': [50, np.nan, 70, 80, np.nan]\n",
        "})\n",
        "print(f\"DataFrame original con NaN:\\n{df_nan}\\n\")\n",
        "print(f\"Cantidad de NaN por columna:\\n{df_nan.isnull().sum()}\\n\")\n",
        "\n",
        "# --- Rellenar con fillna() ---\n",
        "print(\"--- Rellenar con fillna() ---\")\n",
        "# 1. Rellenar todos los valores nulos con cero\n",
        "# fillna() devuelve un NUEVO DataFrame por defecto. Usar inplace=True para modificar el original.\n",
        "df_fillna_cero = df_nan.fillna(0)\n",
        "print(\"DataFrame con NaN rellenados con 0:\")\n",
        "print(df_fillna_cero)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Variación: Rellenar utilizando el valor medio de cada columna\n",
        "# Calculamos la media por columna (ignora NaN por defecto) y la usamos para rellenar\n",
        "medias_columnas = df_nan.mean()\n",
        "print(f\"Medias por columna:\\n{medias_columnas}\\n\")\n",
        "df_fillna_mean = df_nan.fillna(medias_columnas)\n",
        "print(\"DataFrame con NaN rellenados con la media de su columna:\")\n",
        "print(df_fillna_mean)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Variación: Rellenar usando el valor anterior (forward fill) o siguiente (backward fill)\n",
        "df_fillna_ffill = df_nan.fillna(method='ffill') # Rellena con el último valor válido hacia adelante\n",
        "print(\"DataFrame con NaN rellenados con el valor anterior (ffill):\")\n",
        "print(df_fillna_ffill)\n",
        "print(\"\\n\")\n",
        "\n",
        "df_fillna_bfill = df_nan.fillna(method='bfill') # Rellena con el primer valor válido hacia atrás\n",
        "print(\"DataFrame con NaN rellenados con el valor siguiente (bfill):\")\n",
        "print(df_fillna_bfill)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# --- Eliminar con dropna() ---\n",
        "print(\"--- Eliminar con dropna() ---\")\n",
        "# 4. Eliminar FILAS que contengan al menos un valor nulo (axis=0 por defecto)\n",
        "# Esto puede ser muy agresivo si hay muchos NaN dispersos\n",
        "df_dropna_filas = df_nan.dropna() # O dropna(axis=0)\n",
        "print(\"DataFrame después de eliminar filas con CUALQUIER NaN:\")\n",
        "print(df_dropna_filas)\n",
        "print(\"Observa que solo queda la fila sin NaN (si la hubiera).\\n\")\n",
        "\n",
        "# 5. Eliminar COLUMNAS que contengan al menos un valor nulo (axis=1)\n",
        "df_dropna_cols = df_nan.dropna(axis=1)\n",
        "print(\"DataFrame después de eliminar columnas con CUALQUIER NaN:\")\n",
        "print(df_dropna_cols)\n",
        "print(\"Observa que solo quedan las columnas sin NaN (si las hubiera).\\n\")\n",
        "\n",
        "# 6. Variación dropna: Eliminar filas si TODOS sus valores son NaN\n",
        "# Es menos común, se usa how='all'\n",
        "df_nan_all = pd.DataFrame({'X': [np.nan, 1, np.nan], 'Y': [np.nan, 2, np.nan]})\n",
        "df_nan_all.loc[2] = [np.nan, np.nan] # Añadir fila solo con NaN\n",
        "print(f\"DataFrame con fila de solo NaN:\\n{df_nan_all}\\n\")\n",
        "df_dropped_all_nan = df_nan_all.dropna(how='all')\n",
        "print(\"DataFrame después de eliminar filas donde TODOS los valores son NaN:\")\n",
        "print(df_dropped_all_nan)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 7. Variación dropna: Especificar un umbral mínimo de valores no-NaN\n",
        "# thresh=N requiere al menos N valores no-NaN en la fila/columna para mantenerla\n",
        "# Mantener filas con al menos 2 valores NO nulos\n",
        "df_dropna_thresh = df_nan.dropna(thresh=2)\n",
        "print(\"DataFrame después de eliminar filas con MENOS de 2 valores NO nulos:\")\n",
        "print(df_dropna_thresh)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "ZyJY2eP9IUZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Guardar DataFrames ---\")\n",
        "\n",
        "# Supongamos que 'df_final' es nuestro DataFrame resultado del análisis\n",
        "# Usaremos el DataFrame con medias rellenadas como ejemplo\n",
        "df_final = df_fillna_mean\n",
        "print(f\"DataFrame que vamos a guardar:\\n{df_final}\\n\")\n",
        "\n",
        "# --- Guardar en diferentes formatos ---\n",
        "\n",
        "# 1. Exportar el DataFrame a un archivo CSV\n",
        "# index=False: No escribe el índice del DataFrame en el archivo.\n",
        "# encoding='utf-8': Buena práctica para compatibilidad de caracteres.\n",
        "output_csv_file = 'datos_exportados.csv'\n",
        "try:\n",
        "    df_final.to_csv(output_csv_file, index=False, encoding='utf-8', sep=';') # Cambiado sep a ;\n",
        "    print(f\"DataFrame guardado exitosamente en: {output_csv_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar en CSV: {e}\")\n",
        "\n",
        "# 2. Exportar el DataFrame a un archivo Excel\n",
        "# sheet_name: Nombre de la hoja dentro del archivo Excel.\n",
        "# Requiere 'openpyxl': pip install openpyxl\n",
        "output_excel_file = 'datos_exportados.xlsx'\n",
        "try:\n",
        "    df_final.to_excel(output_excel_file, sheet_name='Resultados', index=False)\n",
        "    print(f\"DataFrame guardado exitosamente en: {output_excel_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar en Excel: {e}\")\n",
        "\n",
        "# 3. Convertir el DataFrame a formato JSON\n",
        "# orient='records': Formato común, lista de diccionarios (uno por fila).\n",
        "# Otras opciones: 'split', 'index', 'columns', 'values', 'table'.\n",
        "output_json_file = 'datos_exportados.json'\n",
        "try:\n",
        "    df_final.to_json(output_json_file, orient='records', indent=4) # indent=4 para mejor legibilidad\n",
        "    print(f\"DataFrame guardado exitosamente en: {output_json_file}\")\n",
        "    # Opcional: imprimir el JSON como string\n",
        "    # json_string = df_final.to_json(orient='records', indent=4)\n",
        "    # print(f\"\\nContenido JSON:\\n{json_string}\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar en JSON: {e}\")\n",
        "\n",
        "# 4. Convertir el DataFrame a una tabla HTML\n",
        "# Útil para visualización web o informes rápidos.\n",
        "output_html_file = 'datos_exportados.html'\n",
        "try:\n",
        "    df_final.to_html(output_html_file, index=False, border=1) # border=1 añade bordes a la tabla\n",
        "    print(f\"DataFrame guardado exitosamente en: {output_html_file}\")\n",
        "    # Opcional: imprimir el HTML como string\n",
        "    # html_string = df_final.to_html(index=False, border=1)\n",
        "    # print(f\"\\nContenido HTML:\\n{html_string}\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar en HTML: {e}\")\n",
        "\n",
        "print(\"\\n--- Fin del Script ---\")"
      ],
      "metadata": {
        "id": "qwufbwuQIZjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2bm3Q93TIZmS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}