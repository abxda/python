{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/python/blob/main/UP_Semana_6_Viernes_y_S%C3%A1bado_04_Chat_with_News.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo6ly0KIqpwX"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install -U duckduckgo_search\n",
        "!pip install wordcloud matplotlib\n",
        "!pip install flagembedding\n",
        "!pip install -U spacy\n",
        "!python -m spacy download es_core_news_sm\n",
        "!pip install --quiet openai langchain\n",
        "!pip install install langchain-chroma\n",
        "!pip install pypdf\n",
        "!pip install sentence-transformers\n",
        "!pip install unstructured\n",
        "!pip install ctransformers\n",
        "!pip install -U langchain-community\n",
        "!pip install newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfrllBqmrnLn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from duckduckgo_search import AsyncDDGS\n",
        "import asyncio\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import spacy\n",
        "from newspaper import Article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuCVKVOCZaOp"
      },
      "outputs": [],
      "source": [
        "def extract_article_content(row):\n",
        "    url = row['url']\n",
        "    body = row['body']\n",
        "    try:\n",
        "        article = Article(url)\n",
        "        article.download()\n",
        "        article.parse()\n",
        "        return article.text if article.text else body\n",
        "    except Exception as e:\n",
        "        return body"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-IMhJoorv-W"
      },
      "outputs": [],
      "source": [
        "# Configuraciones para la búsqueda de noticias en Aguascalientes\n",
        "configuraciones = [\n",
        "    {\"idioma\": \"Español\", \"keywords\": \"México\", \"region\": \"mx-es\"}\n",
        "]\n",
        "\n",
        "# Diccionario para almacenar los resultados de noticias por idioma\n",
        "resultados_noticias = {\"Español\": []}\n",
        "\n",
        "async def buscar_noticias(idioma, keywords, region):\n",
        "    async_ddgs = AsyncDDGS()\n",
        "    noticias = await async_ddgs.anews(keywords=keywords, region=region, safesearch='moderate', max_results=25)\n",
        "    return idioma, noticias\n",
        "\n",
        "async def main():\n",
        "    tasks = [buscar_noticias(conf['idioma'], conf['keywords'], conf['region']) for conf in configuraciones]\n",
        "    results = await asyncio.gather(*tasks)\n",
        "    for idioma, noticias in results:\n",
        "        resultados_noticias[idioma].extend(noticias)  # Añadir noticias a la lista correspondiente del idioma\n",
        "        print(f\"Resultados para {idioma}: {len(noticias)} noticias encontradas.\")\n",
        "await main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faKjBFocr9yv"
      },
      "outputs": [],
      "source": [
        "df_noticias = pd.DataFrame(resultados_noticias[\"Español\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7CYVsrxZc6V"
      },
      "outputs": [],
      "source": [
        "# Crear una nueva columna en el DataFrame para almacenar el contenido del artículo\n",
        "df_noticias['full_content'] = df_noticias.apply(extract_article_content, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj6IpO1dd-Mc"
      },
      "outputs": [],
      "source": [
        "df_noticias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ansg6OA03qmZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from langchain.document_loaders import UnstructuredHTMLLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import LanceDB\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAXZ6ykW4Emj"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=350,\n",
        "    chunk_overlap=50,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q2XdXTY5dsz"
      },
      "outputs": [],
      "source": [
        "texts = text_splitter.create_documents(df_noticias[\"full_content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwE12m5T5MD7"
      },
      "outputs": [],
      "source": [
        "documents = text_splitter.split_documents(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tfr2OCf95_Dt"
      },
      "outputs": [],
      "source": [
        "from FlagEmbedding import BGEM3FlagModel\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "embeddings = HuggingFaceEmbeddings(model_name='BAAI/bge-m3',model_kwargs={'device': 'cpu'},encode_kwargs=encode_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgnlhJjDt-s_"
      },
      "outputs": [],
      "source": [
        "#Ejecutar solo si se sstá usando la versión T4\n",
        "#!sudo apt-get update && sudo apt-get install -y cuda-drivers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBoYI5mf5ciy"
      },
      "outputs": [],
      "source": [
        "!pip install colab-xterm #https://pypi.org/project/colab-xterm/\n",
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXqkL6KO5kix"
      },
      "outputs": [],
      "source": [
        "%xterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDSpwwrF5klR"
      },
      "outputs": [],
      "source": [
        "#curl -fsSL https://ollama.com/install.sh | sh\n",
        "#ollama serve & ollama pull llama3\n",
        "#ollama serve & ollama pull phi3:mini\n",
        "#lo tuve que hacer 2 veces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcbnIoI25wSZ"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import Ollama\n",
        "\n",
        "llm = Ollama(model=\"phi3:mini\")\n",
        "response = llm.invoke(\"sabes español?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"que es un llm\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "T82yJrcEKtLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCwwpg1N4sVE"
      },
      "outputs": [],
      "source": [
        "from chromadb.config import Settings\n",
        "import chromadb\n",
        "from langchain.vectorstores import Chroma\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jocUmG6hW89V"
      },
      "outputs": [],
      "source": [
        "persist_directory=\"./chromadbx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjzqKxbybrU_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "om8R_4WC6bW5"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=documents, # text data that you want to embed and store\n",
        "    embedding=embeddings, # used to convert the documents into embeddings\n",
        "    persist_directory=persist_directory, # tells Chroma where to store its data\n",
        "    collection_name=\"noticias_full\" #  gives a name to the collection of embeddings, which will be helpful for retrieving specific groups of embeddings later.\n",
        ")\n",
        "\n",
        "vectordb.persist() # will make the database save any changes to the disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iG27el16k2o"
      },
      "outputs": [],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O99LdC107kzS"
      },
      "outputs": [],
      "source": [
        "query = \"Que está pasando con la ola de calor en méxico, responde en español\"\n",
        "vectordb.similarity_search(query,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvR717UG6J9z"
      },
      "outputs": [],
      "source": [
        "# Initialize an instance of the Ollama model\n",
        "#llm = Ollama(model=\"llama3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuG5HuEe1JY-"
      },
      "outputs": [],
      "source": [
        "query = \"Que está pasando con la ola de calor en méxico, responde en español\"\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
        "respuesta = qa.run(query)\n",
        "print(respuesta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqNpTq9G1JcF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzBRkML91ug3/ktlmY9x5+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}